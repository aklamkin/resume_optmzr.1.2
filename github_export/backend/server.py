from fastapi import FastAPI, HTTPException, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional
import os
import uuid
import json
import re
from datetime import datetime
import requests
from bs4 import BeautifulSoup
import pdfplumber
from docx import Document
from dotenv import load_dotenv
import time
import asyncio

# Load environment variables
load_dotenv()

# Debug: Check if API key is loaded
api_key_check = os.environ.get('GEMINI_API_KEY')
print(f"üîë API Key loaded at startup: {bool(api_key_check)}")
if api_key_check:
    print(f"üîë API Key starts with: {api_key_check[:10]}...")

app = FastAPI(
    title="Resume Optimizer API",
    description="AI-powered resume optimization backend",
    version="1.0.0"
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Pydantic models
class ResumeAnalysisRequest(BaseModel):
    job_description: str
    resume_text: Optional[str] = None

# Helper functions for file processing
def extract_text_from_pdf(file_content: bytes) -> str:
    """Extract text from PDF file"""
    try:
        import io
        pdf_file = io.BytesIO(file_content)
        
        text = ""
        with pdfplumber.open(pdf_file) as pdf:
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n"
        
        return text.strip()
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Failed to extract text from PDF: {str(e)}")

def extract_text_from_docx(file_content: bytes) -> str:
    """Extract text from DOCX file"""
    try:
        import io
        docx_file = io.BytesIO(file_content)
        
        doc = Document(docx_file)
        text = ""
        
        for paragraph in doc.paragraphs:
            text += paragraph.text + "\n"
            
        return text.strip()
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Failed to extract text from DOCX: {str(e)}")

def is_url_only(text: str) -> bool:
    """Check if text is a single URL"""
    text = text.strip()
    # Check if it's a single URL (starts with http/https, no spaces, no newlines)
    url_pattern = r'^https?://[^\s\n]+$'
    return bool(re.match(url_pattern, text))

def scrape_job_description(url: str) -> str:
    """Scrape job description from URL"""
    try:
        # Check for known problematic sites
        if 'linkedin.com' in url.lower():
            raise HTTPException(status_code=400, detail="LinkedIn blocks automated access. Please copy and paste the job description text directly instead of using the URL.")
        
        if 'indeed.com' in url.lower():
            raise HTTPException(status_code=400, detail="Indeed may block automated access. If this fails, please copy and paste the job description text directly.")
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Remove script and style elements
        for script in soup(["script", "style"]):
            script.decompose()
        
        # Try to find job description in common elements
        job_content = ""
        
        # Common job posting selectors
        selectors = [
            '[class*="job-description"]',
            '[class*="job-details"]', 
            '[class*="description"]',
            '[id*="job-description"]',
            '[id*="description"]',
            'main',
            '.content',
            '#content'
        ]
        
        for selector in selectors:
            element = soup.select_one(selector)
            if element:
                job_content = element.get_text(strip=True, separator='\n')
                if len(job_content) > 200:  # If we found substantial content
                    break
        
        # If no specific element found, get all text
        if not job_content or len(job_content) < 200:
            job_content = soup.get_text(strip=True, separator='\n')
        
        # Clean up the text
        lines = [line.strip() for line in job_content.split('\n') if line.strip()]
        cleaned_text = '\n'.join(lines)
        
        # Limit to reasonable length (first 5000 characters)
        if len(cleaned_text) > 5000:
            cleaned_text = cleaned_text[:5000] + "..."
            
        return cleaned_text
        
    except requests.exceptions.RequestException as e:
        if "403" in str(e) or "Forbidden" in str(e):
            raise HTTPException(status_code=400, detail=f"Website blocks automated access. Please copy and paste the job description text directly instead of using the URL.")
        elif "404" in str(e) or "Not Found" in str(e):
            raise HTTPException(status_code=400, detail=f"Job posting not found at this URL. Please check the URL or copy and paste the job description text directly.")
        else:
            raise HTTPException(status_code=400, detail=f"Failed to fetch URL: {str(e)}. Try copying and pasting the job description text directly.")
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"Failed to scrape job description: {str(e)}. Please copy and paste the job description text directly instead of using the URL.")

# Enhanced error response models
class APIError(BaseModel):
    error_type: str  # "service_unavailable", "timeout", "rate_limit", "authentication", "unknown"
    message: str
    retryable: bool
    retry_after_seconds: Optional[int] = None
    details: Optional[str] = None

class RetryableResponse(BaseModel):
    success: bool
    data: Optional[dict] = None
    error: Optional[APIError] = None

# AI Integration using emergentintegrations with enhanced error handling
async def get_ai_response_with_retry(job_description: str, resume_text: str, max_retries: int = 3, retry_delay: int = 5):
    """
    Get AI response with built-in retry logic for handling service overloads
    """
    for attempt in range(max_retries + 1):
        try:
            print(f"ü§ñ AI Analysis Attempt {attempt + 1}/{max_retries + 1}")
            response = await get_ai_response(job_description, resume_text)
            return RetryableResponse(success=True, data={"analysis": response})
            
        except Exception as e:
            error_str = str(e).lower()
            
            # Classify the error type
            if "overloaded" in error_str or "503" in error_str or "unavailable" in error_str:
                error_type = "service_unavailable"
                retryable = True
                retry_after = retry_delay * (attempt + 1)  # Exponential backoff
                message = "AI service is currently overloaded. Please try again in a few moments."
            elif "timeout" in error_str or "timed out" in error_str:
                error_type = "timeout"
                retryable = True
                retry_after = retry_delay
                message = "Request timed out. The service may be experiencing high load."
            elif "rate limit" in error_str or "429" in error_str:
                error_type = "rate_limit"
                retryable = True
                retry_after = 60  # Wait longer for rate limits
                message = "Rate limit exceeded. Please wait a moment before trying again."
            elif "unauthorized" in error_str or "401" in error_str or "invalid api key" in error_str:
                error_type = "authentication"
                retryable = False
                retry_after = None
                message = "Authentication failed. Please check API key configuration."
            else:
                error_type = "unknown"
                retryable = attempt < max_retries  # Only retry for unknown errors if we have attempts left
                retry_after = retry_delay
                message = f"AI service error: {str(e)}"
            
            error_response = APIError(
                error_type=error_type,
                message=message,
                retryable=retryable,
                retry_after_seconds=retry_after,
                details=str(e)
            )
            
            # If this is our last attempt or error is not retryable, return the error
            if attempt >= max_retries or not retryable:
                print(f"‚ùå Final attempt failed: {error_response.message}")
                return RetryableResponse(success=False, error=error_response)
            
            # If retryable, wait and try again
            if retryable and attempt < max_retries:
                print(f"‚è≥ Retrying in {retry_after} seconds... (Attempt {attempt + 1}/{max_retries + 1})")
                await asyncio.sleep(retry_after)
                continue
                
    # Should never reach here, but just in case
    return RetryableResponse(
        success=False, 
        error=APIError(
            error_type="unknown",
            message="Maximum retries exceeded",
            retryable=False
        )
    )

async def get_ai_response(job_description: str, resume_text: str):
    try:
        # Import the emergentintegrations library
        from emergentintegrations.llm.chat import LlmChat, UserMessage
        
        print(f"ü§ñ Starting AI analysis - Job desc: {len(job_description)} chars, Resume: {len(resume_text)} chars")
        
        system_prompt = """You are Elena Rodriguez, a Senior Resume Optimization Specialist with 15+ years of experience at Fortune 500 companies and top recruiting firms. You've personally reviewed over 10,000 resumes and have deep expertise in ATS systems, hiring manager psychology, and industry-specific optimization strategies.

## YOUR MISSION
Conduct a comprehensive resume analysis against the target job description to identify specific, actionable optimization opportunities that will significantly increase the candidate's interview potential.

## ANALYSIS FRAMEWORK

### PHASE 1: STRATEGIC ASSESSMENT
- Map resume content against job requirements with precision scoring
- Identify critical gaps that disqualify candidates vs. enhancement opportunities
- Assess ATS compatibility and keyword optimization potential

### PHASE 2: TACTICAL OPTIMIZATION
- Provide specific text improvements with clear before/after examples
- Prioritize changes by impact level (High/Medium/Low)
- Ensure recommendations maintain authenticity while maximizing relevance

### PHASE 3: COMPETITIVE POSITIONING
- Highlight differentiating factors that set candidate apart
- Suggest quantification opportunities for achievements
- Recommend strategic keyword placement for maximum ATS impact

## OUTPUT REQUIREMENTS

Provide analysis in this exact JSON structure:

```json
{
  "skills_gap": [
    "List specific skills from job description missing or underrepresented in resume"
  ],
  "suggestions": [
    {
      "section": "summary|experience|skills|achievements|education",
      "current_text": "exact text from resume or null if adding new content",
      "suggested_text": "optimized replacement text with specific improvements",
      "reason": "detailed explanation of why this change increases interview potential",
      "impact_level": "High|Medium|Low",
      "priority": 1-10
    }
  ],
  "ats_keywords": [
    "prioritized list of keywords from job description to incorporate"
  ],
  "overall_score": "X/100 - Current resume strength with specific reasoning and improvement potential"
}
```

## OPTIMIZATION PRINCIPLES
1. **Relevance First**: Every suggestion must directly address job requirements
2. **Quantify Impact**: Include numbers, percentages, and measurable outcomes
3. **ATS Intelligence**: Strategic keyword placement without stuffing
4. **Authentic Enhancement**: Improve existing accomplishments rather than fabricating
5. **Hiring Manager Perspective**: Consider what decision-makers actually want to see

## CRITICAL CONSTRAINTS - DO NOT VIOLATE
‚ö†Ô∏è **ZERO FABRICATION RULE**: You are STRICTLY PROHIBITED from adding, inventing, or fabricating ANY information that is not explicitly present in the original resume. This includes but is not limited to:

‚ùå **FORBIDDEN FABRICATIONS**:
- Skills, technologies, tools, or software not mentioned
- Quantified metrics, percentages, or numbers not provided
- Specific achievements, projects, or accomplishments not listed
- Company names, job titles, or dates not present
- Certifications, education, or training not mentioned
- Any specific details, facts, or claims not in original content

‚úÖ **ONLY ALLOWED**:
- Rewriting existing content for better clarity and impact
- Improving grammar, structure, and professional language
- Enhancing presentation of information already present
- Better organization and formatting of existing details
- Strategic keyword placement using existing qualifications
- Suggesting removal of weak or irrelevant content

**ENHANCEMENT PRINCIPLE**: If it's not explicitly in the resume, don't add it. Your role is to polish and optimize existing content, never to invent new information.

## QUALITY STANDARDS
- Suggestions must be specific and immediately actionable
- Replacements should be professional, industry-appropriate, and compelling
- Each recommendation includes clear reasoning tied to job requirements
- Priority ranking helps candidate focus on highest-impact changes

Analyze with the precision of a top recruiting firm and the insight of an industry expert."""

        # Create AI chat instance
        api_key = os.environ.get('GEMINI_API_KEY')
        if not api_key:
            print("‚ùå Gemini API key not found")
            raise HTTPException(status_code=500, detail="Gemini API key not configured")
            
        print("üîë API key found, creating chat instance...")
        chat = LlmChat(
            api_key=api_key,
            session_id=f"resume_analysis_{uuid.uuid4()}",
            system_message=system_prompt
        ).with_model("gemini", "gemini-2.0-flash")

        # Create user message
        user_message = UserMessage(
            text=f"""
            JOB DESCRIPTION:
            {job_description}
            
            CURRENT RESUME:
            {resume_text}
            
            Please analyze and provide optimization suggestions in the specified JSON format.
            """
        )

        print("üì§ Sending message to AI...")
        # Get AI response
        response = await chat.send_message(user_message)
        print("üì• Received AI response")
        
        # Clean up the response - remove markdown code blocks if present
        cleaned_response = str(response)
        if "```json" in cleaned_response:
            # Extract JSON from markdown code blocks
            start_marker = "```json"
            end_marker = "```"
            start_index = cleaned_response.find(start_marker) + len(start_marker)
            end_index = cleaned_response.find(end_marker, start_index)
            if end_index > start_index:
                cleaned_response = cleaned_response[start_index:end_index].strip()
        
        print("‚úÖ AI analysis completed successfully")
        return cleaned_response
        
    except Exception as e:
        print(f"‚ùå AI analysis error: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"AI analysis failed: {str(e)}")

async def get_cover_letter_response_with_retry(job_description: str, resume_text: str, max_retries: int = 3, retry_delay: int = 5):
    """
    Get cover letter response with built-in retry logic for handling service overloads
    """
    for attempt in range(max_retries + 1):
        try:
            print(f"üìù Cover Letter Generation Attempt {attempt + 1}/{max_retries + 1}")
            response = await get_cover_letter_response(job_description, resume_text)
            return RetryableResponse(success=True, data=response)
            
        except Exception as e:
            error_str = str(e).lower()
            
            # Classify the error type (same logic as AI analysis)
            if "overloaded" in error_str or "503" in error_str or "unavailable" in error_str:
                error_type = "service_unavailable"
                retryable = True
                retry_after = retry_delay * (attempt + 1)
                message = "AI service is currently overloaded. Please try again in a few moments."
            elif "timeout" in error_str or "timed out" in error_str:
                error_type = "timeout"
                retryable = True
                retry_after = retry_delay
                message = "Request timed out. The service may be experiencing high load."
            elif "rate limit" in error_str or "429" in error_str:
                error_type = "rate_limit"
                retryable = True
                retry_after = 60
                message = "Rate limit exceeded. Please wait a moment before trying again."
            elif "unauthorized" in error_str or "401" in error_str or "invalid api key" in error_str:
                error_type = "authentication"
                retryable = False
                retry_after = None
                message = "Authentication failed. Please check API key configuration."
            else:
                error_type = "unknown"
                retryable = attempt < max_retries
                retry_after = retry_delay
                message = f"Cover letter generation error: {str(e)}"
            
            error_response = APIError(
                error_type=error_type,
                message=message,
                retryable=retryable,
                retry_after_seconds=retry_after,
                details=str(e)
            )
            
            if attempt >= max_retries or not retryable:
                print(f"‚ùå Cover letter generation final attempt failed: {error_response.message}")
                return RetryableResponse(success=False, error=error_response)
            
            if retryable and attempt < max_retries:
                print(f"‚è≥ Retrying cover letter generation in {retry_after} seconds...")
                await asyncio.sleep(retry_after)
                continue
                
    return RetryableResponse(
        success=False, 
        error=APIError(
            error_type="unknown",
            message="Maximum retries exceeded",
            retryable=False
        )
    )

async def get_cover_letter_response(job_description: str, resume_text: str):
    try:
        # Import the emergentintegrations library
        from emergentintegrations.llm.chat import LlmChat, UserMessage
        
        system_prompt = """You are Marcus Chen, Executive Career Strategist and former Head of Talent Acquisition at Microsoft, Google, and Tesla. You've crafted winning cover letters for C-suite executives, product managers, engineers, and creatives across all industries. Your letters have achieved a 73% interview rate - significantly above industry average.

## YOUR EXPERTISE
- Psychology of hiring decisions and what captivates hiring managers
- Industry-specific communication styles and expectations  
- Compelling storytelling that connects candidate value to business needs
- Strategic positioning that differentiates candidates in competitive markets

## MISSION
Create TWO strategically crafted cover letters that position the candidate as the ideal solution to the employer's specific needs, demonstrating clear value proposition and cultural fit.

## STRATEGIC FRAMEWORK

### ANALYSIS PHASE
- Extract key requirements and pain points from job description
- Identify candidate's strongest differentiating factors from resume
- Map compelling narratives that connect experience to role needs

### POSITIONING PHASE  
- Craft opening hooks that immediately demonstrate relevance
- Build evidence-based value propositions with quantified achievements
- Weave in cultural fit and company knowledge where applicable

### DIFFERENTIATION PHASE
- Highlight unique combinations of skills and experience
- Address potential concerns or gaps proactively
- Position candidate as the obvious choice among alternatives

## DUAL VERSION REQUIREMENTS

### VERSION 1: EXECUTIVE BRIEF (250 words)
**Target**: Busy executives who scan quickly
- **Opening**: Role + top credential + immediate value
- **Core Body**: Single most compelling requirement match with quantified impact
- **Close**: Confident next step request with enthusiasm

### VERSION 2: COMPREHENSIVE NARRATIVE (450-600 words)  
**Target**: Detailed reviewers and HR professionals
- **Opening**: Role + engaging hook + clear value preview
- **Evidence Block 1**: Primary requirement with detailed success story
- **Evidence Block 2**: 2-3 additional requirements with specific achievements  
- **Cultural Connection**: Company knowledge + alignment + enthusiasm
- **Strategic Close**: Value summary + professional call to action

## EXCELLENCE STANDARDS
1. **Immediate Relevance**: First sentence establishes job-candidate fit
2. **Quantified Impact**: Include specific numbers, percentages, outcomes
3. **Authentic Voice**: Professional but personable, confident not arrogant
4. **Strategic Keyword Use**: Natural incorporation of job description language
5. **Compelling Narrative**: Tells a story of progressive success and fit

## CRITICAL CONSTRAINTS - DO NOT VIOLATE
‚ö†Ô∏è **ZERO FABRICATION RULE**: You are STRICTLY PROHIBITED from adding, inventing, or fabricating ANY information that is not explicitly present in the original resume. This includes but is not limited to:

‚ùå **FORBIDDEN FABRICATIONS**:
- Skills, experiences, or qualifications not mentioned in resume
- Specific metrics, numbers, percentages, or quantified achievements not provided
- Company names, project details, or accomplishments not listed
- Technologies, tools, or certifications not present in original
- Any dates, locations, or specific facts not mentioned
- Achievements, awards, or recognition not in resume

‚úÖ **ONLY ALLOWED**:
- Enhancing presentation of existing information from resume
- Improving language and tone while staying factually accurate
- Better connecting existing experience to job requirements
- Reorganizing existing content for maximum impact
- Using existing achievements to demonstrate value proposition
- Professional phrasing of actual background and experience

**ENHANCEMENT PRINCIPLE**: Work exclusively with what the candidate actually has. Your expertise is in presentation and positioning, not content creation.

## OUTPUT FORMAT
Return exactly this JSON structure:

```json
{
  "short_version": "Complete 250-word cover letter ready for immediate use",
  "long_version": "Complete 450-600 word cover letter ready for immediate use"
}
```

## QUALITY CHECKLIST
- ‚úì Addresses specific company and role (not generic)
- ‚úì Quantified achievements from resume integrated naturally  
- ‚úì Clear value proposition in opening paragraph
- ‚úì Professional tone with personality
- ‚úì Strong call to action in closing
- ‚úì Error-free and immediately usable

Write with the precision of a Fortune 500 communications team and the insight of a top executive recruiter."""

        # Create AI chat instance
        api_key = os.environ.get('GEMINI_API_KEY')
        if not api_key:
            raise HTTPException(status_code=500, detail="Gemini API key not configured")
            
        chat = LlmChat(
            api_key=api_key,
            session_id=f"cover_letter_{uuid.uuid4()}",
            system_message=system_prompt
        ).with_model("gemini", "gemini-2.0-flash")

        # Create user message
        user_message = UserMessage(
            text=f"""
            JOB DESCRIPTION:
            {job_description}
            
            CANDIDATE'S RESUME:
            {resume_text}
            
            Please generate TWO professional cover letters (short and long versions) that specifically address the requirements in the job description and highlight the most relevant qualifications from the resume. Make them compelling, specific, and professional.
            
            Return the response in JSON format with both versions.
            """
        )

        # Get AI response
        response = await chat.send_message(user_message)
        
        # Clean up the response
        cleaned_response = str(response).strip()
        
        # Try to parse as JSON first
        try:
            if "```json" in cleaned_response:
                # Extract JSON from markdown code blocks
                start_marker = "```json"
                end_marker = "```"
                start_index = cleaned_response.find(start_marker) + len(start_marker)
                end_index = cleaned_response.find(end_marker, start_index)
                if end_index > start_index:
                    cleaned_response = cleaned_response[start_index:end_index].strip()
            
            parsed_response = json.loads(cleaned_response)
            
            return {
                "cover_letter_id": str(uuid.uuid4()),
                "short_version": parsed_response.get("short_version", ""),
                "long_version": parsed_response.get("long_version", ""),
                "created_at": datetime.utcnow()
            }
        except json.JSONDecodeError:
            # Fallback: treat as single cover letter
            return {
                "cover_letter_id": str(uuid.uuid4()),
                "short_version": cleaned_response[:1000] + "..." if len(cleaned_response) > 1000 else cleaned_response,
                "long_version": cleaned_response,
                "created_at": datetime.utcnow()
            }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Cover letter generation failed: {str(e)}")

# API Routes

@app.get("/api/")
async def root():
    return {
        "message": "Resume Optimizer API v1.0", 
        "status": "healthy",
        "endpoints": {
            "health": "/api/health",
            "analyze": "/api/analyze",
            "generate_cover_letter": "/api/generate-cover-letter"
        }
    }

@app.get("/api/test-ai")
async def test_ai():
    """Test AI integration"""
    try:
        from emergentintegrations.llm.chat import LlmChat, UserMessage
        
        api_key = os.environ.get('GEMINI_API_KEY')
        if not api_key:
            return {"error": "API key not found"}
        
        chat = LlmChat(
            api_key=api_key,
            session_id="test_session",
            system_message="You are a helpful assistant. Respond with JSON: {\"test\": \"working\"}"
        ).with_model("gemini", "gemini-2.0-flash")
        
        user_message = UserMessage(text="Test message")
        response = await chat.send_message(user_message)
        
        return {"success": True, "response": str(response)}
        
    except Exception as e:
        return {"error": str(e)}

@app.get("/api/health")
async def health_check():
    return {"status": "healthy", "version": "1.0.0"}

@app.post("/api/analyze")
async def analyze_resume(
    job_description: str = Form(...),
    resume_text: Optional[str] = Form(None),
    resume_file: Optional[UploadFile] = File(None)
):
    """Analyze resume against job description using AI - supports file upload and URL scraping"""
    try:
        # Process job description (detect URL vs text)
        processed_job_desc = job_description
        if is_url_only(job_description):
            print(f"üåê Detected URL, scraping job description from: {job_description}")
            processed_job_desc = scrape_job_description(job_description)
        
        # Process resume (file vs text)
        processed_resume_text = ""
        
        if resume_file:
            print(f"üìÅ Processing uploaded file: {resume_file.filename}")
            
            # Validate file type
            if not resume_file.filename:
                raise HTTPException(status_code=400, detail="No filename provided")
            
            file_ext = resume_file.filename.lower().split('.')[-1]
            if file_ext not in ['pdf', 'docx']:
                raise HTTPException(status_code=400, detail="Only PDF and DOCX files are supported")
            
            # Read file content
            file_content = await resume_file.read()
            
            # Extract text based on file type
            if file_ext == 'pdf':
                processed_resume_text = extract_text_from_pdf(file_content)
            elif file_ext == 'docx':
                processed_resume_text = extract_text_from_docx(file_content)
            
            if not processed_resume_text.strip():
                raise HTTPException(status_code=400, detail="No text could be extracted from the uploaded file")
                
        elif resume_text:
            processed_resume_text = resume_text.strip()
        else:
            raise HTTPException(status_code=400, detail="Either resume_text or resume_file must be provided")
        
        # Validate we have both job description and resume
        if not processed_job_desc.strip():
            raise HTTPException(status_code=400, detail="Job description is required")
        
        if not processed_resume_text.strip():
            raise HTTPException(status_code=400, detail="Resume content is required")
        
        print(f"‚úÖ Processing analysis - Job desc: {len(processed_job_desc)} chars, Resume: {len(processed_resume_text)} chars")
        
        # Get AI analysis with retry capability
        ai_result = await get_ai_response_with_retry(
            processed_job_desc, 
            processed_resume_text
        )
        
        # Check if AI analysis was successful
        if not ai_result.success:
            # Return detailed error information for frontend to handle
            raise HTTPException(
                status_code=503,  # Service Unavailable
                detail={
                    "error_type": ai_result.error.error_type,
                    "message": ai_result.error.message,
                    "retryable": ai_result.error.retryable,
                    "retry_after_seconds": ai_result.error.retry_after_seconds,
                    "details": ai_result.error.details
                }
            )
        
        return {
            "analysis_id": str(uuid.uuid4()),
            "analysis": ai_result.data["analysis"],
            "original_resume": processed_resume_text,
            "job_description": processed_job_desc,
            "created_at": datetime.utcnow(),
            "source_info": {
                "job_source": "url" if is_url_only(job_description) else "text",
                "resume_source": "file" if resume_file else "text",
                "file_type": resume_file.filename.split('.')[-1] if resume_file else None
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/generate-cover-letter")
async def generate_cover_letter(
    job_description: str = Form(...),
    resume_text: Optional[str] = Form(None),
    resume_file: Optional[UploadFile] = File(None)
):
    """Generate a cover letter based on resume and job description - supports file upload and URL scraping"""
    try:
        # Process job description (detect URL vs text)
        processed_job_desc = job_description
        if is_url_only(job_description):
            processed_job_desc = scrape_job_description(job_description)
        
        # Process resume (file vs text)
        processed_resume_text = ""
        
        if resume_file:
            # Validate file type
            if not resume_file.filename:
                raise HTTPException(status_code=400, detail="No filename provided")
            
            file_ext = resume_file.filename.lower().split('.')[-1]
            if file_ext not in ['pdf', 'docx']:
                raise HTTPException(status_code=400, detail="Only PDF and DOCX files are supported")
            
            # Read file content
            file_content = await resume_file.read()
            
            # Extract text based on file type
            if file_ext == 'pdf':
                processed_resume_text = extract_text_from_pdf(file_content)
            elif file_ext == 'docx':
                processed_resume_text = extract_text_from_docx(file_content)
                
        elif resume_text:
            processed_resume_text = resume_text.strip()
        else:
            raise HTTPException(status_code=400, detail="Either resume_text or resume_file must be provided")
        
        # Validate we have content
        if not processed_job_desc.strip() or not processed_resume_text.strip():
            raise HTTPException(status_code=400, detail="Both job description and resume content are required")
        
        # Generate cover letter with retry capability
        result = await get_cover_letter_response_with_retry(
            processed_job_desc,
            processed_resume_text
        )
        
        # Check if cover letter generation was successful
        if not result.success:
            # Return detailed error information for frontend to handle
            raise HTTPException(
                status_code=503,  # Service Unavailable
                detail={
                    "error_type": result.error.error_type,
                    "message": result.error.message,
                    "retryable": result.error.retryable,
                    "retry_after_seconds": result.error.retry_after_seconds,
                    "details": result.error.details
                }
            )
        
        return result.data
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8001)